---
title: "SAGE Implicatures human experiment"
author: "PT"
date: "2023-08-23"
output: github_document
---

```{r}
library(tidyverse)
library(tidyboot)
library(cspplot)
library(brms)
```

```{r}
d <- read_csv("../data/results_8_sage-interpretations-fc-439-anonymized.csv")
# remove prolific IDs etc
#d <- d %>% select(-prolific_pid, -prolific_session_id, -prolific_study_id)
#d %>% write_csv("../data/results_8_sage-interpretations-fc-439-anonymized.csv")

head(d)  
nrow(d)

# manually inspect the favorite animal responses
d %>% filter(is.na(condition)) %>% pull(response) %>% unique()
```

# preprocessing & exclusions

Due to a bug, the responses require a step of correction wherein responses to the vignette about Jesse need to be corrected. Specifically, the duplicated response option for the target and the competitor have to be removed, otherwise the selected option assignment does not work. This is done by removing the competitor option (too little and baseline conditions, item_id 22). This is done for columns options_list and options_order. Below, an exploratory analysis excluding this item can be found.

Exclude participants who didn't answer with an animal from the list.
```{r}
d_cleaned_ids <- d %>% filter((tolower(response) %in% c("koala bear", "kola", "kola bear", "kuala bear", "koala beat", "koala", "koala-bear", "kowala bear", "koala beer", "sloth", "sloths", "ant-eater", "ant eater", "anteater")) ) %>% pull(submission_id)
d_cleaned <- d %>% filter(submission_id %in% d_cleaned_ids)
# retrieve number of subjects from whom we keep the data
d_cleaned_ids %>% unique() %>% length()

nrow(d_cleaned)
# no exclusions based on language
d_cleaned %>% pull(languages) %>% unique()

d_main <- d_cleaned %>% filter(!is.na(condition))
```

Apply processing to get which response option was actually chosen: 
```{r}
d_main <- d_main %>% rowwise() %>%
  mutate(
    split_order = str_split(options_order, fixed("|")),
    split_options = str_split(options_list, fixed("|"))
  ) %>% rowwise() %>% mutate(
   chosen_option_ind = which(tolower(split_options) == tolower(response)),
   chosen_option = split_order[chosen_option_ind]
  )
#d_main %>% write_csv("../data/results_8_sage-interpretations-fc-439-cleaned.csv")
```

# descriptive stats with relevant grouping

```{r}
d_main %>% count(condition)
d_main %>% count(condition, chosen_option)
d_main %>% group_by(item_id, condition) %>% count()
d_main %>% count(item_id) %>% arrange(n)

# compute target proportion
d_summary <- d_main %>% 
  mutate(resp_cat_binary = ifelse(chosen_option == "target_prejacent", 1 , 0)) %>%
  group_by(condition) %>%
  summarise(target_prop = mean(resp_cat_binary))

d_summary
```

# plots

```{r}
# compute bootstrapped CIs
d_summary_boot <- d_main %>% 
  mutate(resp_cat_binary = ifelse(chosen_option == "target_prejacent", 1 , 0)) %>% group_by(condition) %>%
  tidyboot_mean(column = resp_cat_binary)

# write out sumamry data
# d_summary_boot %>% write_csv("../data/results_sage-interpretations-fc_439_summary.csv")

d_summary_boot %>%
  ggplot(., aes(x = condition, y = mean, fill = condition, ymin=ci_lower, ymax=ci_upper)) +
  geom_col() +
  geom_hline(yintercept=0.25) +
  geom_errorbar(width=0.2) +
  theme_csp()
```

A supplementary materials plot like QA CogSci with a break down of response types in the columns.
```{r}
d_main_byCategory_summary <- d_main %>% group_by(condition) %>%
  mutate(n = n()) %>%
  group_by(condition, chosen_option) %>%
  mutate(num_chosen_option = n()) %>%
  summarize(option_prop = num_chosen_option / n) %>% unique()

d_main_byCategory_summary %>%
  mutate(chosen_option = factor(chosen_option, levels = c("target_prejacent", "competitor_prejacent", "distractor_1_prejacent", "distractor_2_prejacent"), labels = c("target", "competitor", "distractor_1", "distractor_2"))) %>%
  ggplot(., aes(x = condition, y = option_prop, fill = chosen_option)) +
  geom_col() +
  theme_csp() +
  ylab("proportion of chosen interpretations") 
```

# stats

Run a multinomial regression: response type against an intercept.
```{r}
options(mc.cores = parallel::detectCores())

d_main_fct <- d_main %>% mutate(
  chosen_option = factor(chosen_option, levels = c("target_prejacent", "competitor_prejacent", "distractor_1_prejacent", "distractor_2_prejacent")),
  condition = factor(condition, levels = c("baseline", "too_little", "too_much", "marked", "irrelevant"))
)
contrasts(d_main_fct$chosen_option)
contrasts(d_main_fct$condition)

model_interceptOnly <- brm(
  chosen_option ~ 1, 
  data = d_main_fct, 
  family = "categorical",
  iter = 5000,
  cores = 4,
)
summary(model_interceptOnly)
```

For a multinomial model with a main effect of condition the ESS is too low and the model does not converge (a model with by-item random intercepts does not converge), so binarized responses are analysed (1 if response was target, 0 otherwise).
```{r, eval=FALSE}
d_main_fct_binary <- d_main_fct %>%
  mutate(binary_result = ifelse(chosen_option == "target_prejacent", 1, 0))

model_logistic_byCondition <- brm(
  binary_result ~ condition + (1 | item_id),
  data = d_main_fct_binary, 
  family = "bernoulli",
  iter = 3000,
  cores = 4,
#  control = list(max_treedepth = 15),
)
summary(model_logistic_byCondition)
```

# exploratory

As a sanity check, we exclude vignette 22 from the analysis to see if there is any qualitative difference. Based on visual comparison of the plots, there seems to be no difference whatsoever. 
```{r}
# compute bootstrapped CIs
d_summary_boot_wo22 <- d_main %>% 
  filter(item_id != 22) %>%
  mutate(resp_cat_binary = ifelse(chosen_option == "target_prejacent", 1 , 0)) %>% group_by(condition) %>%
  tidyboot_mean(column = resp_cat_binary)

d_summary_boot_wo22 %>%
  ggplot(., aes(x = condition, y = mean, fill = condition, ymin=ci_lower, ymax=ci_upper)) +
  geom_col() +
  geom_hline(yintercept=0.25) +
  geom_errorbar(width=0.2) +
  theme_csp()
```
